{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/isear_processed.csv',index_col=0, names=['text','emotion'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  During the period of falling in love, each tim...      joy\n",
       "1         When I was involved in a traffic accident.     fear\n",
       "2  When I was driving home after  several days of...    anger\n",
       "3  When I lost the person who meant the most to me.   sadness\n",
       "4  The time I knocked a deer down - the sight of ...  disgust"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anger      1096\n",
       "disgust    1096\n",
       "sadness    1096\n",
       "shame      1096\n",
       "fear       1095\n",
       "joy        1094\n",
       "guilt      1093\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the emotion dict to encode the label\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "labels = df['emotion']\n",
    "\n",
    "for k in range(len(labels.unique())):\n",
    "    emotion_dict[labels.unique()[k]] = k\n",
    "    \n",
    "print('Creating the emotion dict to encode the label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_labels = np.array(list(labels.map(lambda x: emotion_dict[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seq_length = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open('../data/embedding/glove.6B.100d.txt') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, 'f', sep=' ')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the embedding\n",
    "\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "num_words = min(MAX_NUM_WORDS, len(tokenizer.word_index) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i >= MAX_NUM_WORDS:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, encoded_labels, stratify=encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).type(torch.LongTensor), torch.from_numpy(np.array(y_train)).type(torch.LongTensor))\n",
    "val_data = TensorDataset(torch.from_numpy(X_test).type(torch.LongTensor), torch.from_numpy(y_test).type(torch.LongTensor))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (token_embedding): Embedding(9064, 100)\n",
      "  (position_embedding): Embedding(50, 100)\n",
      "  (transfo_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (self_attention): SelfAttention(\n",
      "        (to_keys): Linear(in_features=100, out_features=400, bias=True)\n",
      "        (to_queries): Linear(in_features=100, out_features=400, bias=True)\n",
      "        (to_values): Linear(in_features=100, out_features=400, bias=True)\n",
      "        (merge_heads): Linear(in_features=400, out_features=100, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=100, out_features=200, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=200, out_features=100, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_probs): Linear(in_features=100, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from basic_transformer import Transformer\n",
    "\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "num_classes = len(labels.unique())\n",
    "\n",
    "model = Transformer(100,4,1,num_words, seq_length,num_classes,True,embedding_matrix)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30   Loss: 1.915957   val_loss: 1.914337 val_accuracy: 0.208659\n",
      "Epoch: 2/30   Loss: 1.831618   val_loss: 1.833256 val_accuracy: 0.321335\n",
      "Epoch: 3/30   Loss: 1.828008   val_loss: 1.856948 val_accuracy: 0.275952\n",
      "Epoch: 4/30   Loss: 1.769396   val_loss: 1.788203 val_accuracy: 0.361502\n",
      "Epoch: 5/30   Loss: 1.747059   val_loss: 1.781728 val_accuracy: 0.362546\n",
      "Epoch: 6/30   Loss: 1.766260   val_loss: 1.771320 val_accuracy: 0.369327\n",
      "Epoch: 7/30   Loss: 1.789414   val_loss: 1.769282 val_accuracy: 0.383412\n",
      "Epoch: 8/30   Loss: 1.749119   val_loss: 1.783310 val_accuracy: 0.362024\n",
      "Epoch: 9/30   Loss: 1.574376   val_loss: 1.744958 val_accuracy: 0.400104\n",
      "Epoch: 10/30   Loss: 1.623026   val_loss: 1.737799 val_accuracy: 0.416797\n",
      "Epoch: 11/30   Loss: 1.578789   val_loss: 1.745431 val_accuracy: 0.402713\n",
      "Epoch: 12/30   Loss: 1.635651   val_loss: 1.742455 val_accuracy: 0.403756\n",
      "Epoch: 13/30   Loss: 1.681242   val_loss: 1.744960 val_accuracy: 0.405321\n",
      "Epoch: 14/30   Loss: 1.728574   val_loss: 1.731319 val_accuracy: 0.417319\n",
      "Epoch: 15/30   Loss: 1.761063   val_loss: 1.731703 val_accuracy: 0.413146\n",
      "Epoch: 16/30   Loss: 1.697810   val_loss: 1.739658 val_accuracy: 0.412102\n",
      "Epoch: 17/30   Loss: 1.725709   val_loss: 1.735967 val_accuracy: 0.414189\n",
      "Epoch: 18/30   Loss: 1.606103   val_loss: 1.730897 val_accuracy: 0.425143\n",
      "Epoch: 19/30   Loss: 1.874800   val_loss: 1.751966 val_accuracy: 0.399061\n",
      "Epoch: 20/30   Loss: 1.684147   val_loss: 1.764580 val_accuracy: 0.384455\n",
      "Epoch: 21/30   Loss: 1.797612   val_loss: 1.724601 val_accuracy: 0.428273\n",
      "Epoch: 22/30   Loss: 1.634197   val_loss: 1.719421 val_accuracy: 0.433490\n",
      "Epoch: 23/30   Loss: 1.782053   val_loss: 1.742376 val_accuracy: 0.413146\n",
      "Epoch: 24/30   Loss: 1.647887   val_loss: 1.716500 val_accuracy: 0.436098\n",
      "Epoch: 25/30   Loss: 1.666541   val_loss: 1.715514 val_accuracy: 0.436098\n",
      "Epoch: 26/30   Loss: 1.626182   val_loss: 1.724219 val_accuracy: 0.433490\n",
      "Epoch: 27/30   Loss: 1.752123   val_loss: 1.735085 val_accuracy: 0.418362\n",
      "Epoch: 28/30   Loss: 1.680699   val_loss: 1.722520 val_accuracy: 0.427230\n",
      "Epoch: 29/30   Loss: 1.709621   val_loss: 1.713359 val_accuracy: 0.442879\n",
      "Epoch: 30/30   Loss: 1.548283   val_loss: 1.717335 val_accuracy: 0.436620\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "EPOCHS = 30\n",
    "for e in range(EPOCHS):\n",
    "    model.train()\n",
    "\n",
    "    for text_sequences, targets in train_loader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        out = model(text_sequences)\n",
    "        loss = criterion(out, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "    cur_loss = loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = []\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "    \n",
    "    val_loss = []\n",
    "    \n",
    "    for text_sequences,targets in val_loader:\n",
    "        with torch.no_grad():\n",
    "            out = model(text_sequences)\n",
    "            loss = criterion(out, targets)\n",
    "            val_loss.append(loss.item())\n",
    "            y_pred+=list(out.detach().numpy().argmax(axis=1))\n",
    "            y_true+=list(targets.detach().numpy())\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    print(\"Epoch: {}/{}  \".format(e+1, EPOCHS),\n",
    "            \"Loss: {:.6f}  \".format(cur_loss),\n",
    "              \"val_loss: {:.6f}\".format(np.mean(val_loss)),\n",
    "             \"val_accuracy: {:.6f}\".format(accuracy_score(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emotion_detection] *",
   "language": "python",
   "name": "conda-env-emotion_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
