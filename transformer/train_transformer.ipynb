{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-alpha0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/isear_processed.csv',index_col=0, names=['text','emotion'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>During the period of falling in love, each tim...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>When I was involved in a traffic accident.</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>When I was driving home after  several days of...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>When I lost the person who meant the most to me.</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>The time I knocked a deer down - the sight of ...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  emotion\n",
       "0  During the period of falling in love, each tim...      joy\n",
       "1         When I was involved in a traffic accident.     fear\n",
       "2  When I was driving home after  several days of...    anger\n",
       "3  When I lost the person who meant the most to me.   sadness\n",
       "4  The time I knocked a deer down - the sight of ...  disgust"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sadness    1096\n",
       "anger      1096\n",
       "disgust    1096\n",
       "shame      1096\n",
       "fear       1095\n",
       "joy        1094\n",
       "guilt      1093\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the emotion dict to encode the label\n"
     ]
    }
   ],
   "source": [
    "emotion_dict = {}\n",
    "labels = df['emotion']\n",
    "\n",
    "for k in range(len(labels.unique())):\n",
    "    emotion_dict[labels.unique()[k]] = k\n",
    "    \n",
    "print('Creating the emotion dict to encode the label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "encoded_labels = np.array(list(labels.map(lambda x: emotion_dict[x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/arnaudstiegler/miniconda3/envs/emotion_detection/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "seq_length = 50\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, encoded_labels, stratify=encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, training on CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_on_gpu=torch.cuda.is_available()\n",
    "\n",
    "if(train_on_gpu):\n",
    "    print('Training on GPU.')\n",
    "else:\n",
    "    print('No GPU available, training on CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# create Tensor datasets\n",
    "train_data = TensorDataset(torch.from_numpy(X_train).type(torch.LongTensor), torch.from_numpy(np.array(y_train)).type(torch.LongTensor))\n",
    "val_data = TensorDataset(torch.from_numpy(X_test).type(torch.LongTensor), torch.from_numpy(y_test).type(torch.LongTensor))\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 64\n",
    "\n",
    "# make sure the SHUFFLE your training data\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (token_embedding): Embedding(9064, 50)\n",
      "  (position_embedding): Embedding(50, 50)\n",
      "  (transfo_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (self_attention): SelfAttention(\n",
      "        (to_keys): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (to_queries): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (to_values): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (merge_heads): Linear(in_features=100, out_features=50, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (self_attention): SelfAttention(\n",
      "        (to_keys): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (to_queries): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (to_values): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (merge_heads): Linear(in_features=100, out_features=50, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((50,), eps=1e-05, elementwise_affine=True)\n",
      "      (ff): Sequential(\n",
      "        (0): Linear(in_features=50, out_features=100, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=100, out_features=50, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (to_probs): Linear(in_features=50, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from basic_transformer import Transformer\n",
    "\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "num_classes = len(labels.unique())\n",
    "\n",
    "model = Transformer(50,2,2,num_words, seq_length,num_classes)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10   Loss: 1.944658  \n",
      "Epoch: 2/10   Loss: 1.943278  \n",
      "Epoch: 3/10   Loss: 1.946526  \n",
      "Epoch: 4/10   Loss: 1.943841  \n",
      "Epoch: 5/10   Loss: 1.950224  \n",
      "Epoch: 6/10   Loss: 1.939775  \n",
      "Epoch: 7/10   Loss: 1.937046  \n",
      "Epoch: 8/10   Loss: 1.945402  \n",
      "Epoch: 9/10   Loss: 1.951010  \n",
      "Epoch: 10/10   Loss: 1.946500  \n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "for e in range(EPOCHS):\n",
    "    model.train(True)\n",
    "\n",
    "    for text_sequences, targets in train_loader:\n",
    "\n",
    "        opt.zero_grad()\n",
    "\n",
    "        out = model(text_sequences)\n",
    "        loss = criterion(out, targets)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # clip gradients\n",
    "        # - If the total gradient vector has a length > 1, we clip it back down to 1.\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "\n",
    "        opt.step()\n",
    "        #sch.step()\n",
    "\n",
    "\n",
    "    print(\"Epoch: {}/{}  \".format(e+1, EPOCHS),\n",
    "            \"Loss: {:.6f}  \".format(loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:emotion_detection]",
   "language": "python",
   "name": "conda-env-emotion_detection-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
